# ----------------------------------
# Redis Configuration
# ----------------------------------
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# ----------------------------------
# Cache Configuration
# ----------------------------------
# Distance threshold for cache hits (0-2, lower = stricter)
# 0.0 = exact match only
# 0.15 = default (recommended, allows semantic similarity)
# 0.30 = more lenient (higher hit rate, more false positives)
CACHE_DISTANCE_THRESHOLD=0.15

# Time-to-live for cache entries (seconds)
# 604800 = 7 days (default)
# 86400 = 1 day
CACHE_TTL=604800

# Redis index name (change if running multiple environments)
CACHE_INDEX_NAME=semantic_cache

# ----------------------------------
# Embedding Model Configuration
# ----------------------------------
# Default embedding model
# For OllamaEmbeddingProvider:
#   - embeddinggemma (768 dims, RECOMMENDED)
# For GemmaEmbeddingProvider:
#   - google/embeddinggemma-300m (requires HF auth) (768 dims)
EMBEDDING_MODEL=embeddinggemma

# Embedding output dimension (only used by GemmaEmbeddingProvider with Matryoshka)
# Options: 768 (best quality), 512 (balanced), 256 (efficient), 128 (minimal)
# ⚠️ When changing dimensions, run: make cache-clear
EMBEDDING_OUTPUT_DIMENSION=768

# ----------------------------------
# Ollama Configuration
# ----------------------------------
# Only needed if using OllamaEmbeddingProvider
# Requires: brew install ollama && ollama pull embeddinggemma
# See: docs/OLLAMA_SETUP.md
OLLAMA_BASE_URL=http://localhost:11434

# ----------------------------------
# HuggingFace Configuration
# ----------------------------------
# Only needed if using GemmaEmbeddingProvider (direct via sentence-transformers)
# Requires: huggingface-cli login (one-time setup)
# Get token from: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_your_token_here

# ----------------------------------
# API Configuration
# ----------------------------------
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# ----------------------------------
# Optional: OpenAI API
# ----------------------------------
# For LLM integration examples
# OPENAI_API_KEY=sk-your_key_here
